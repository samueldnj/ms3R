# Methods

## British Columbia's flatfish fishery

British Columbia's complex of right-eyed flounders is 
a spatially diverse and interacting group. While the
there are several right-eyed flounders in BC waters, we 
will focus only on Dover sole (*Microstomus pacficus*), 
English sole (*Parophrys vetulus*), and southern rock sole 
(*Lepidopsetta bilineata*), which we refer to as rock sole 
here. Taken together, we denote the Dover, English and rock sole 
multi-stock complex as the DER complex. We chose the DER complex
as it is managed as part of the BC groundfish fishery, all three 
species have the same management unit boundaries, and are
targeted at different times of the year by the same commercial
bottom trawl fleet. 

The DER complex is managed in three spatially distinct stock
areas, which line up with aggregates of BC groundfish management
areas, which are themselves made up of groups of Pacific Fishery
Management Areas [@PRIFMP2015]. From North to South, the first extends 
from Dixon Entrance, north of Haida Gwaii, south through 
Hecate Strait; we refer to it as the Hecate Strait/Haida 
Gwaii (HSHG) stock, and it corresponds to BC groundfish 
area 5CDE. The second stock area is Queen Charlotte Sound 
(QCS), or BC groundfish area 5AB. Finally, the third
area extends along the West Coast of Vancouver Island (WCVI) 
from its northern tip down to the entrance to Juan de Fuca Strait,
and corresponds to BC groundfish area 3CD.

All species in the DER complex have experienced exploitation
since before 1956. At that time, Dover sole was only 
lightly exploited, with full commercial exploitation
beginning only in the 1970s. In contrast, English and rock 
sole fisheries have been very active in the Hecate Strait
for the whole historical time series, with fishing activity 
in other areas more variable over time (plots).

- Stock status and reference points as estimated
by hierSCAL (table)




## Simulation model framework

Our simulation framework had an operating
model component and management procedure component. The
stochastic operating model simulated the responses of a 
spatially stratified multi-species complex of fishes to 
trawl fleet fishing effort in each of the three stock areas. 
Total fishing effort was not restricted, but the effort in each  
area was allocated so that no catch exceeded the TAC for 
any species in that area, but at least one species' 
TAC was fully utilised in each area.

The operating model (OM) component was a multi-species,
multi-stock age- and sex-structured population dynamics model 
(Appendix A). We conditioned the OM by fitting it as 
a stock assessment model to commercial and survey data
for the DER complex, including commercial catch, CPUE,
and catch-at-age/length, and fishery independent survey 
biomass indices, and survey catch-at-age/length. Given 
the low volume of biological data from recent time 
periods, we used a hierarchical multi-species and multi-stock
assessment model formulation with shrinkage priors on 
tge natural mortality, stock-recruitment steepness, 
trawl survey catchability, and selectivity-at-length 
parameters. We refer readers to Appendix A for more details.

Closed loop simulations applied the management procedure
iteratively in the following 5 steps over the $T$ 
years of the projection:

1. Use an assessment method to determine stock
status of the complex, either using data pooling,
hierarchical assessments, or single-stock assessments; 
2. Apply a harvest control rule to determine
total allowable catch, and then allocate TAC 
among species if using a data-pooling method;
3. Allocate effort to fully realise at least
one TAC in each stock area;
4. Generate realised catches from effort with
updated catch rates;
5. Update stochastic population dynamics and
generate new observation data.

Each set of $T$ projection years was repeated
100 times to integrate over observation errors 
and recruitment process errors.

### Operating Model


### Management Procedures

### Surplus production stock assessment models

Management procedures determined stock
status using a flexible process-error surplus 
production model. The flexibility allowed the
same model to be used for all assessment complex
configurations, ranging from data-pooled single
stock assessments with no shrinkage priors to hierarchical
multi-species and multi-stock assessments. We defined this
model in Template Model Builder, extending
a model from our previous research [@kristensen2015tmb;
@johnson2018evaluating]. For hierarchical model formulations, 
we applied shrinkage priors to survey catchability 
and intrinsic growth rate (Appendix B). In total,
five model configurations were defined:

1. Hierarchical multi-stock (9 stocks, sharing info)
2. Single-stock (9 stocks, independent)
3. Hierarchical coastwide (3 species)
4. Hierarchical data-pooled (3 stocks)
5. Data-pooled coastwide (1 stock)


Data was pooled by simple summation of both
catch and biomass indices across species within
each area. This reflects that each species' survey 
biomass index was an estimate of trawlable biomass, 
so the pooled index was an estimate of trawlable
complex biomass available to the survey. We also
summed the CPUE observations for the commercial
trawl fleets, under the assumption that the same
trawl effort was used to calculate the unstandardised
CPUE observations (i.e. the CPUE series had the same
denominators); however, this assumption was inaccurate 
as the species-specific CPUE had species-specific effort
derived from the fishing sets that caught each species, 
and not all fishing sets catch all three species. Ignoring 
the inaccuracy biased the data-pooled CPUE and introduced
more variability, which we decided was acceptable
for research purposes. Under coastwide assessments, 
each survey (pooled or separate) was considered as a 
separate index of the same population.

We extended our surplus production stock assessment model 
to account for differences between the operating model
dynamics and the assessment model assumptions about
yield curve shape and ratios of exploitable biomass
to spawning biomass. We followed the JABBBA-Select
formulation for biomass assessments to add both
features [@winker2020jabba]. Skew in the operating 
model yield curves was added to all AMs by switching to
a Pella-Tomlinson formulation [@pella1969generalized], 
and the difference between exploitable biomass and 
spawning biomass was added by using the equilibrium 
model developed for the JABBA-Select model 
[@winker2020jabba]. We used the skewed yield curve
for all model formulations, including data aggregated
methods, where we re-derived the ratio between unfished
and optimal biomass in each case. The exploitable
and spawning biomass ratio estimates were used in all cases
except the data-pooling, spatially disaggregated 
assessment (3 in above list), under which the 
estimates introduced a persistent bias in the fits
to stock indices. Details of our derivation
of skew and biomass ratio parameters are given in 
Appendix B.

At each time step $t$, the AM estimated production model 
equilibria $B_{MSY}$ and $U_{MSY}$, and an expected 
biomass estimate $\hat{B}_{t+1}$ for the following 
time step.


### Harvest control rule

To set catch limits for a given stock, or data-pooled complex,
we applied a simple ramped precuationary harvest control 
rule, following Canadian federal policy [@DFO2006A-Harvest-Strat]:
\begin{equation}
U_{t+1} = \left\{ \begin{array}{ll}
            0 & \hat{B}_{t+1} \leq .4\hat{B}_{MSY} \\
            \frac{\hat{B}_{t+1} - .4\hat{B}_{MSY}}{(.6 - .4)\hat{B}_{MSY}} U_{MSY} & 
                .4 < \hat{B}_{t+1}/\hat{B}_{MSY} \leq .6 \\
            \hat{U}_{MSY} & \hat{B}_{t+1} \geq .6\hat{B}_{MSY}
          \end{array} \right.
\end{equation}
Where $\hat{B}_{MSY}$, $\hat{U}_{MSY}$, and $\hat{B}_{t+1}$  
were estimated by the assessment model either for 
an individual species, individual stocks, or a 
data-pooled complex.

Total allowable catch (TAC) was then set as the product
of target harvest rate and projected biomass
\begin{equation}
TAC_{t+1} = U_{t+1} \cdot \hat{B}_{t+1}.
\end{equation}
In situations where the assessment model scale matched
the operating model scale, then TACs were passed directly
to the effort allocation model. In other cases when data were
pooled or stock structure was ignored, we defined rules
for allocating TAC among areas and species.

For splitting TACs within an area or across spatial
strata when data has been pooled, we split them according to 
the relative contribution of each individual index to the 
pooled data. For example, if the pooled biomass 
index for stock area $p$ in time step $t$ was the sum of species
specific indices in the same area, i.e,
\begin{equation}
I_{p,t} = \sum_s I_{s,p,t},
\end{equation}
then the TAC for species $s$ is apportioned as
\[
TAC_{s,p,t+1} = \frac{I_{s,p,t}}{I_{p,t}} TAC_{p,t+1}.
\]
The analogous apportionment holds for all data aggregation
MPs.

### Fishing effort, fishing mortality, and optimal yield

We allocated maximum fishing effort to each area. 
Maximum effort was defined as the amount required to
fully utilise the TAC of at least one species, 
but never exceed any of the three species' TACs. 
Effort was then supplied to the operating model to
generate realised fishing mortality among
species and stock areas as
\begin{equation}
F_{s,p,f,t} = \bar{q}^{(F)}_{s,p,f} * E_{p,f,t},
\end{equation}
where $\bar{q}^{(F)}_{s,p,f}$ is the 
ratio of estimated fishing mortality rates to 
fishing effort in the last year of the conditioning 
assessment. Historical fishing effort was estimated by taking 
the average ratio
\begin{equation}
E_{p,f,t} = \bar{\frac{C_{s,p,f,t}}{I'_{s,p,f,t}}}
\end{equation}
where $I'_{s,p,f,t}$ is unstandardized commercial
CPUE (in kg/hour), and $C_{s,p,f,t}$ is the total 
catch in kt. We averaged this ratio over species within a stock area to 
account for years in which there were missing CPUE
observations (**WHY NOT TAKE MAX?? WHAT ABOUT SMOOTHING??
CHECK UNITS, COULD PROBABLY DO WITH A PLOT**).

We chose to use maximum effort over an effort dynamics
model because of (i) its simplicity and (ii) its similarity 
to other MSE simulations for BC fisheries. We considered 
including an effort dynamics model to allocate a pool 
of effort over the three areas [@hilborn1987general;
@walters1999multispecies], but determined that this was
not necessary for determining the management performance 
of the multiple assessment models that we are testing.
Furthermore, although the BC groundfish fishery balances
the utilisation of many more than three TACs in practice,
avoiding fully utilising TACs to account for future bycatch,
we found that the maxmium effort model effectively 
simulated the TAC under-utilisations for two species 
out of the three. Finally, BC sablefish, herring, and
outside yelloweye rockfish use full TAC utilisation 
in their management simulations
[@cox2019evaluating;**INSERT HERRING and OYE CSAS HERE**],
under the assumption that full TAC utilisation provides
and upper bound on the management risk.

We defined a multi-species maximum sustainable yield 
$MSY_{MS,p}$ for each area $p$ by using the relationship 
between trawl fishing effort and species-specific 
fishing mortality rates. For a given value of trawl 
fishing effort $E$, we computed a complex yield curve
by summing the yield curves of all three flatfishes 
in the area at the corresponding fishing mortality rates
\begin{equation}
Y_{MS,p} (E) = \sum_{s} Y_{s,p} (q^{(F)}_{s,p} E),
\end{equation}
where $Y_{MS,p}$ is the complex yield curve for stock
area $p$ with respect to trawl effort, and $Y_{s,p}$ is the
species specific yield curve for stock area $p$ with
respect to fishing mortality. The optimal trawl effort
$E_{MSY,p}$ was then derived as the solution 
to ${dY_{MS,p}}/{dE} = 0$, with corresponding 
equilibrium yield $Y_{MS,p}(E_{MSY,p})$. Our method
is similar to other approaches to defining multi-species 
equilibria [@mueter2006using], but explicitly includes
the differential catchability of technically interacting 
species.



## Simulation experiments and performance

For the main experiment, we ran a total of $20$ 
simulations, made up of fully factorial combinations 
of the five management procedures and four harvest control
rule settings. We ran 100 replicates of each OM/MP, 
each initialised with a unique random seed, thereby integrating 
over all stochastic processes. To eliminate the
effect of random variation between simulations, 
each simulation was initialised with the same set
of 100 random seeds. We ran extra replicates until the 
sample size of 100 was reached when AMs failed to
converge in the closed loop simulations, the rate of which
was variable among MPs. The operating model was run for 32 
years, which was two generation lengths for Dover sole, 
the species with the longest generation time in the 
DER complex. Generation time was calculated as the 
average age at maturity of the female spawning population 
in the absence of fishing [@seber1997estimation].

DEFINE THE FOUR MPs somewhere!!

We tested our 20 MPs against a single operating model 
scenario conditioned by the maximum likelihood estimates
of OM assessment. For all DER stocks, the main differences
between OM replicates were in simulated survey observation 
errors and recruitment process error deviations. Simulated 
log-normal observation and process errors were randomly drawn 
with the same standard deviations, and bias corrected so that
asymptotic averages matched the expected value
\begin{align}
I_{s,p,f,t} &= q_{s,p,f} \cdot B_{s,p,f,t} \cdot exp( \tau_{s,p,f} \cdot \delta_{s,p,f,t} - 0.5\tau^2_{s,p,f} ) \\
R_{s,p,t}   &= \hat{R}_{s,p,t} \cdot \cdot exp( \sigma_{s,p} \cdot \epsilon_{s,p,t} - 0.5\sigma^2_{s,p} ) 
\end{align}
where the above variables are defined in Table A1. Recruitment
process errors are simulated from before the end of the
historical period, replacing the equlibrium values used
in years where the conditioning assessment was unable to
estimate process errors due to a lack of age composition
data. 



### OM scenarios?? MAY TAKE OUT

There are already 20 sims (as defined above), so

Survey CV scenarios:
1. Current $\tau_{s,p,f}$ value from conditioning;
2. Half current SD: $\tau_{s,p,f,proj} = 0.5 \cdot \tau_{s,p,f}$;
3. Twice current SD: $\tau_{s,p,f,proj} = 2 \cdot \tau_{s,p,f}$;
4. Four times current SD: $\tau_{s,p,f,proj} = 4 \cdot \tau_{s,p,f}$


### Management procedures

We tested five MPs corresponding to the five assessment 
model configurations outlined above. We chose to restrict
ourselves to the AM configuration only, as this would
allow us to focus on the management performance
of the range of models under different data quality 
scenarios, rather than the interaction between the
assessment model and other management procedure components.

### Omniscient manager simulations

We measured our MP performance against a simulated
omniscient manager. An omniscient manager is aware of
all the consequences of their actions, and is able to
adapt the management to meet certain objectives. We found
that comparing to an omnisicient manager was preferable 
to using standard MSE metrics, such as probability of avoiding
limit depletion levels, as most stocks were in a healthy
state (i.e. above $B_{MSY}$). Being in a healthy state 
means that the stock behaves more like
a developing fishery [@walters1998evaluation], and the 
standard catch and biomass depletion metrics are less 
sensitive to differences in the structure of the MP.

We implemented the omniscient manager as an optimisation
of future fishing effort by area, with the objective
function defined as
\begin{equation}
\mathcal{O}  = \sum_{s,p} \left[
                  \begin{array}{l}
                   -\log(\bar{C}_{s,p,\cdot}) + \\ 
                  % \mathcal{P}_{dep}(B_{s,p,t}/B_{MSY,s,p}) +
                  \mathcal{P}_{closed}(C_{s,p,\cdot}) +
                  % \mathcal{P}_{AAV}(C_{s,p,\cdot}) +
                  % \mathcal{P}_{diff}(C_{s,p,\cdot}) +
                    \mathcal{P}_{diff}(E_{p,\cdot}) + \\
                  % \mathcal{P}_{init}(C_{s,p,t_{MP}}) +
                    \mathcal{P}_{init}(E_{p,t_{MP}}) \end{array} \right]
\end{equation}
where the objective is to maxmimise average catch 
$\bar{C}_{s,p,\cdot}$ for each stock and species over the
projection period. Penalty functions $\mathcal{P}$ were 
applied for:

1. biomass being outside the interval
$[.4B_{MSY,s,p},1.2B_{MSY,s,p}$ ($\mathcal{P}_{dep}$);
2. catch being below the historical minimum ($\mathcal{P}_{closed}$);
3. annual average variation above 30% ($\mathcal{P}_{closed}$);
4. annual changes in catch and effort being above 
30% and 20%, respectively ($\mathcal{P}_{diff}$).
5. difference between historical catch and effort 
above 20% and 10% ($\mathcal{P}_{init}$).

We defined penalty functions so that inside
the desired region the penalty was zero, but outside
the desired region the penalty grew as a cubic function. 
So, for example, a penalty designed to keep a measurement 
$x$ above a the desired region boundary $\epsilon$ is of 
the form
\begin{equation}
\mathcal{P}(x ~|~ \epsilon) = \left\{
  \begin{array}{ll}
    0 & x \geq \epsilon, \\
    |x - \epsilon|^2 & x < epsilon. \\
  \end{array} \right. 
\end{equation}
This form has a several advantages over
simple linear penalties, or a logarithmic barrier
penalty [@srinivasan2008tracking]. First, the cubic 
function makes the boundary threshold $\epsilon$ a soft 
boundary, which is able to be crossed if doing favours 
another portion of the objective function, and because
cubics stick closer to the $x$-axis when $|x-\epsilon| < 1$
this boundary is softer than lower degree polynomials. Second, 
making the penalty zero in the desirable region stops
the objective function from favouring regions far
from the boundaries of penalty functions, as a logarithmic
function would, for example, favouring overly conservative
effort series to keep biomass far from the lower depletion
boundary. Third, the cubic form of the penalty outside
the desired region means that the penalty function and its
first two derivatives are continuous with $x$ (**CHECK**),
allowing quasi-newton optimisation methods to be applied. Last,
the cubic polynomial actually favours small excursions
outside of the desired region when it is a net increase
in the objective function, as cubics stick closer to the
$x$-axis than lower degree polynomials.

Each penalty function is applied with a weighting, which
we used as tuning parameters. Tuning was required to balance
the relative contribution of each penalty, depending
on whether it was applied to a time series or point value,
and also to achieve realistic time series of effort or catch.
For example, commercial harvesters are unable to double or triple
effort in a short period of time, as this would require significant
capital investment or a large increase in human resources. 
Similarly, in practice harvesters are reluctant to allow catch 
to increase by more than 10% - 20% per year (**REACH OUT TO
TRAWL FOR INPUT/POSSIBLE CITATION HERE**). Similarly,
there are job-security implications for large sudden drops in
fishing effort. **Tuning criteria?**

We used a cubic spline of effort in each area to reduce
the number of free parameters in the optimisation. For each
area, 9 knot points were distributed across the full 40 year
projection, making them spaced by 5 years. We padded
the omniscient manager simulations by an extra eight
years over the stochastic simulations to avoid any
possible end effects of the spline entering the 
performance metric calculations. Effort splines
were constrained to be between 0 and 50 units, by
replacing any value outside that range with the closest
value inside the range (i.e. negative values by *zero*,
large values by 50).

We ran the omniscient manager simulation for every random
seed that was used in the stochastic MP simulations. By doing so, 
we assured that an omniscient manager simulation was available
for every set of observation and process errors a stochastic MP 
was exposed to.


### Performance metrics


We measured the performance of the stochastic MPs by comparing
the realised catch and biomass trajectories to those
of the omniscient manager simulations. For each random
seed, the relative and absolute loss of catch and biomass
was calculated as [@walters1998evaluation]:
\begin{align}
L_{abs} &= \sum_{t} | X_{t,MP} - X_{t,omni} |, \\
L_{rel} &= \sum_{t} (X_{t,MP} - X_{t,omni})/X_{t,omni}, 
\end{align}
where the $X_{t,MP}$ values are either catch or spawning
biomass series from the MP runs or the omniscient manager
simulation. Each loss function was calculated on the 
appropriate scale for the MP; that is, the single stock 
and full multi-stock MPs calculate loss for all 9 stocks, 
while the data pooled and coastwide MPs calculate loss on 
the aggregate level. Using the appropriate scale
avoids consideration of the TAC allocation method in
the MP performance. When repeated over all random seed values, 
the loss functions generate a distribution of biomass and 
catch loss, which we compare for performance of each 
stochastic MP.


### Sensitivity runs

Given the need for informative prior distributions to stabilise
the assessment model behaviour in simulations, we also
conducted some sensitivity analyses. Sensitivity
runs focused on the prior distributions applied to
the Bmsy and Umsy values used in
Sensitivity runs:
1. Bmsy prior CV = 0.1, 0.5, 1.0
2. Random Bmsy prior mean drawn from the conditioning 
assessment's posterior?
3. Loosened prior?


