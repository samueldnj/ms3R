# Methods

## British Columbia's flatfish fishery

British Columbia's multi-species complex of 
right-eyed flounders is a technically interacting 
group of flatfishes managed across the whole
BC coast. Although there are several right-eyed 
flounders in BC waters, we focus on Dover sole 
(*Microstomus pacficus*), English sole 
(*Parophrys vetulus*), and southern rock sole (*Lepidopsetta 
bilineata*), which we refer to hereafter as rock 
sole. Taken together, we denote the Dover, English and rock sole 
multi-stock complex as the DER complex. We chose this DER complex
because harvesting is managed as part of the BC 
multi-species groundfish fishery, all three species have 
the same management unit boundaries, and individual
species are targeted at different times of the year by 
the same commercial bottom trawl fleet. 

The DER complex is managed in three spatially distinct stock
areas, which line up with aggregates of BC groundfish management
areas, which are themselves made up of groups of Pacific Fishery
Management Areas [@PRIFMP2015]. From North to South, the first 
stock area extends from Dixon Entrance, north of Haida Gwaii, 
south through Hecate Strait; we refer to it as the Hecate Strait/Haida 
Gwaii (HSHG) stock, and it corresponds to BC groundfish 
area 5CDE. The second stock area is Queen Charlotte Sound 
(QCS), or BC groundfish area 5AB. Finally, the third
area extends along the West Coast of Vancouver Island (WCVI) 
from its northern tip down to the entrance to Juan de Fuca Strait,
and corresponds to BC groundfish area 3CD. [ADD MAP]

Although the DER complex has been exploited since 
at least 1956, at that time Dover sole was only 
lightly exploited, with full commercial exploitation
beginning only in the 1970s (Fig. 1, first column). 
In contrast, English and rock sole fisheries have been 
very active since 1956 in the HSHG area since, where the 
largest biomass is concentrated for both species. In 
contrast English and rock sole fishing activity 
in QCS and WCVI areas is more variable 
over time (Figure 1, rows 2 and 3).

Despite a long history of explotitation, and in some cases
recovery from near collapse, most DER complex stocks were 
in a relatively health state by 2016, with current spawning
biomasses above 80% of $B_{MSY}$, and all but three cases 
at or above $B_{MSY}$ (Table 1). 
Moreover, some stocks were actively recovering from their
historic low biomasses, like English sole in HSHG, and 
Rock sole in HSHG and WCVI.



## Closed loop simulation framework

Our simulation framework had a stochastic operating
model component and an assessment model component. The
operating model simulated population dynamics 
of a spatially stratified, multi-species flatfish complex
in response to a multi-species trawl fishery in each of 
the three stock areas. Although total fishing effort 
was not restricted across the entire area, effort 
in each individual area was allocated such that
no species-/area-specific catch exceeded the 
species-/area-specific TAC. Within an area,
fishing effort was allowed to increase until at least
one species-/area-specific TAC was fully caught.

Closed-loop feedback simulations projected
population dynamics for all 9 stocks forward
in time for $T = 32$ years, with annual simulated 
assessments, harvest decisions, and catch
removed from the population from 2017 - 2048. 
The following four steps summarise the 
closed-loop simulation procedure for each
projection year $t$:

1. Update stochastic population dynamics and
generate new catch $C_{s,p,t}$ from effort, 
and new observation data $I_{s,p,f,t}$ 
(table ref), aggregate obsservation data 
if using a data-pooled method;
2. Apply an assessment model to estimate the
spawning biomass for the following year 
$\hat{B}_{s,p,t+1}$;
3. Apply a harvest rate to generate a total
allowable catch: 
$TAC_{s,p,t+1} = U_{s,p} \cdot \hat{B}_{s,p,t+1}$;
4. Allocate effort to fully realise at least
one TAC in each stock area (tabref for Baranov}:
$E_{p,f,t+1} = \min_{s} \{ E_{s,p,f,t+1} ~|~ C_{s,p,f,t+1} = TAC_{s,p,f,t+1} \}$;


Each simulation consisting of $T = 32$ projection years was 
repeated 100 times to integrate over stochasticity
in recruitment and relative abundance observations. 

### Operating Model

The operating model (OM) was a multi-species,
multi-stock age- and sex-structured population 
dynamics model (Johnson and Cox, in prep). Population 
model parameters were estimated by fitting a hierarchical
age-structured model to data from the
real DER complex (Johnson and Cox in prep).

#### Fishing mortality, fishing effort, and multi-species maximum yield

Fishing mortality for individual stocks was 
driven by a single commercial trawl fishing
effort in each area. Commercial effort
was scaled to species-specific fishing 
mortality using 

Multi-species maximum yield for each area
depends on productivity and catchability 
of each individual species in the area 
[@punt2011calculating; Johnson and Cox in prep]. 
We defined multi-species MSY for stock-area $p$ as
\begin{equation}
MSY_{MS,p} = \max_{E} Y_{MS} 
    \left E, q_{1,p}, q_{2,p}, q_{3,p}, Q_p \right),
\end{equation}
where $E_p$ is the total commercial trawl 
fishing effort in area $p$, $q_{s,p}$ is the 
commerical trawl catchability coefficient scaling
fishing effort to fishing mortality for species $s$ 
in area $p$, and $Q_p$ is a matrix
of life-history parameters for all DER complex species
in area $p$. The function $Y_{MS}$
is the total multi-species yield in area $p$ as 
a function of fishing effort $E_p$, which is
defined as the sum of species-specific equilibrium
yields
\begin{equation}
Y_{MS,p} \left(E_p, q_{1,p}, q_{2,p}, q_{3,p}, Q_p \right)
 = \sum^3_{s=1} Y_{SS,s,p} (E_p, q_{s,p}, Q_{s,p} ),
\end{equation}
where $Q_{s,p}$ is the slice of matrix $Q_p$ 
containing life history paramteers for 
species $s$, and the function $Y_{SS,s,p}$ 
is the traditional single-species yield curve
but as a function of effort and not fishing
mortality.



### Assessment models and data generation

Assessment models and the simulated assessment
data are defined in the following sections. 

#### Surplus production stock assessment models

At each time step $t$, the assessment models
were used to estimate an expected 
biomass estimate $\hat{B}_{t+1}$ for the following 
time step.

Simulated annual asssessments were used to
estimated harvestable biomass via
a state-space Schaefer production model
[@schaefer1957some; @punt2002evaluation]. We extended the
@johnson2018evaluating hierarchical state-space
model to allow all assessment complex configurations,
ranging from data-pooled single-stock assessments
with no hierarchical structure, to a full
hierarchical multi-species and multi-stock
assessment. We defined the state-space
Schaefer model in Template Model Builder 
[@kristensen2015tmb]. For hierarchical model formulations, 
we applied shrinkage priors to survey catchability 
and intrinsic growth rate (Appendix). 

We further modified our original surplus production 
stock assessment model better approximate the
biomass-yield relationship and ratios of exploitable
biomass to spawning biomass underlying the 
age-/sex-structured model [@pella1969generalized;
@winker2020jabba]. Details of our modifications are
in the appendix.

In total, five model configurations were defined:

1. Total aggregation (1 stock)
2. Species Pooling (3 stocks)
3. Spatial Pooling (3 species)
4. Single-stock (9 stocks, independent)
5. Hierarchical multi-stock (9 stocks, sharing info)


#### Data generation for AMs

Time series of catch and biomass indices
were generated for fitting the simulated
assessment models. Catch-per-unit-of-effort
(CPUE) indices were generated from the 
commercial fleets from 1976 - 1995 
(historical) and 1995 - 2016 (modern), 
and survey trawlable biomass indices were
generated for the Hecate Strait assemblage
survey from 1984 - 2002, and in the Synoptic
survey from 2003 - 2048. We outline the
biomass index data generation methods for 
stock specific AMs and data-pooled AMs below.

Biomass indices for individual stocks depended
on the nature of the index. Commercial
CPUE indices were defined as
\begin{equation}
I_{s,p,f,t} = \frac{C_{s,p,f,t}}{E_{p,f,t}},
\end{equation}
where $C_{s,p,f,t}$ was commercial landings
by fleet $f$ of species $s$ from area $p$ at time
$t$, and $E_{p,f,t}$ was commercial fishing
effort expened in area $p$ by fleet $f$ at
time $t$, with both catch and effort required
to be positive. Survey biomass indices
were scaled from survey


Catch data were pooled by summation, and 
the index data depended on the nature
of the index. For Assemblage and Synoptic 
survey biomasss indices, pooled indices 
without observation error were defined as
\begin{align} 
I^{pooled}_{s,f,t}  & = \sum_{p} I(I_{s,p,f,t} > 0) \cdot q_{s,p,f} \cdot B_{s,p,f,t}, \\
I^{pooled}_{p,f,t}  & = \sum_{s} I(I_{s,p,f,t} > 0) \cdot q_{s,p,f} \cdot B_{s,p,f,t}, \\
I^{pooled}_{f,t}    & = \sum_{s,p} I(I_{s,p,f,t} > 0) \cdot q_{s,p,f} \cdot B_{s,p,f,t},
\end{align}
where $I^{pooled}_{s,f,t}$ is the spatially
pooled index for species $s$, $I^{pooled}_{p,f,t}$ 
is a species pooled index for area $p$, 
$I^{pooled}_{f,t}$ is the totally aggregated 
index, and $I(I_{s,p,f,t} > 0)$ is the indicator
function that takes value $1$ when the index
from fleet $f$ for species $s$ in stock area $p$
existed and 0 when it didn't (i.e. the survey
leg in area $p$ was running that year). For
indices from commercial fleets, we defined
the pooled catch-per-unit-of effort (CPUE) index
as
\begin{align} 
I^{pooled}_{s,f,t}  & = \frac{\sum_{p} C_{s,p,f,t}}{\sum_{p} E_{p,f,t} }, \\
I^{pooled}_{p,f,t}  & = \frac{\sum_{s} C_{s,p,f,t}}{ E_{p,f,t} }, \\
I^{pooled}_{f,t}    & = \frac{\sum_{s,p} C_{s,p,f,t}}{ \sum_{p} E_{p,f,t} },
\end{align}


#### Target harvest rates

We used a constant target harvest rate for each species, 
which was derived from the multi-species maximum yield. 

To set catch limits for a given stock, or data-pooled complex,
we applied a constant target harvest rate. We tested two
harvest rates, which were either the single-species $U_{MSY,SS}$,
or multi-species $U_{MSY,MS}$ optimal harvest rates derived 
from operating model equilibrium yield curves. We computed
optimal harvest rates for data-pooled or coast-wide assessment 
model structures by summing the optimal yield $MSY$ and 
exploitable biomass $B_{MSY}$ values of the component 
stocks, e.g. for a data pooled complex in the HSHG stock area,
the multi-species optimal harvest rate was calculated as
\begin{equation}
U_{MSY,HSHG,MS} = \frac{\sum_{s} MSY_{s,HSHG,MS} }{ \sum_{s} B_{MSY,s,HSHG,MS} },
\end{equation}
where $MSY_{s,HSHG,MS}$ is the optimal yield for species $s$
in the HSHG stock area from the multi-species effort-yield
curve defined in section X above, and $B_{MSY,s,HSHG,MS}$ is
the equilibrium spawning biomass that produces $MSY_{s,HSHG,MS}$.

<!-- ramped precuationary harvest control 
rule, following Canadian federal policy [@DFO2006A-Harvest-Strat]:
\begin{equation},
U_{t+1} = \left\{ \begin{array}{ll}
            0 & \hat{B}_{t+1} \leq .4\hat{B}_{MSY} \\
            \frac{\hat{B}_{t+1} - .4\hat{B}_{MSY}}{(.6 - .4)\hat{B}_{MSY}} U_{MSY} & 
                .4 < \hat{B}_{t+1}/\hat{B}_{MSY} \leq .6 \\
            \hat{U}_{MSY} & \hat{B}_{t+1} \geq .6\hat{B}_{MSY}
          \end{array} \right.
\end{equation}
Where $\hat{B}_{MSY}$, $\hat{U}_{MSY}$, and $\hat{B}_{t+1}$  
were estimated by the assessment model either for 
an individual species, individual stocks, or a 
data-pooled complex. -->

Total allowable catch (TAC) was then set as the product
of target harvest rate and projected biomass
\begin{equation}
TAC_{t+1} = U \cdot \hat{B}_{t+1},.
\end{equation}
where $U$ is the optimal harvest rate for either the 
single-species or multi-species equilibrium yield curves,
and stock aggregation level. In management procedures where 
the assessment model estimated biomass for each individual 
stock (i.e. single-stock and hierarchical multi-stock AMs), 
then TACs were passed directly to the effort allocation 
model. In the remaining procedures where data were pooled or 
stock structure was ignored, we allocated the pooled TAC 
among areas and species.  **DELTA TAC UP**

For splitting TACs within an area or across spatial
strata when data had been pooled, we split them according to 
the relative contribution of each individual index to the 
pooled data. For example, if the pooled biomass 
index for stock area $p$ in time step $t$ was the sum of species
specific indices in the same area, i.e,
\begin{equation}
I_{p,t} = \sum_s I_{s,p,t},
\end{equation}
then the TAC for species $s$ is apportioned as
\[
TAC_{s,p,t+1} = \frac{I_{s,p,t}}{I_{p,t}} TAC_{p,t+1}.
\]
The analogous apportionment holds for all data aggregation
MPs.




<!-- We allocated maximum fishing effort to each area. 
Maximum effort was defined as the amount required to
fully utilise the TAC of at least one species, 
but never exceed any of the three species' TACs. 
Effort was then supplied to the operating model to
generate realised fishing mortality among
species and stock areas as
\begin{equation}
F_{s,p,f,t} = \bar{q}^{(F)}_{s,p,f} * E_{p,f,t},
\end{equation}
where $\bar{q}^{(F)}_{s,p,f}$ is the 
ratio of estimated fishing mortality rates to 
fishing effort in the last year of the conditioning 
assessment. Historical fishing effort was estimated by taking 
the average ratio
\begin{equation}
E_{p,f,t} = \bar{\frac{C_{s,p,f,t}}{I'_{s,p,f,t}}}
\end{equation}
where $I'_{s,p,f,t}$ is unstandardized commercial
CPUE (in kg/hour), and $C_{s,p,f,t}$ is the total 
catch in kt. We averaged this ratio over species within a stock area to 
account for years in which there were missing CPUE
observations (**WHY NOT TAKE MAX?? WHAT ABOUT SMOOTHING??
CHECK UNITS, COULD PROBABLY DO WITH A PLOT**). -->

We chose to use maximum effort over an effort dynamics
model because of (i) its simplicity and (ii) its similarity 
to other MSE simulations for BC fisheries. We considered 
including an effort dynamics model to allocate a pool 
of effort over the three areas [@hilborn1987general;
@walters1999multispecies], but determined that this was
not necessary for determining the management performance 
of the multiple assessment models that we are testing.
Furthermore, although the BC groundfish fishery balances
the utilisation of many more than three TACs in practice,
and avoids fully utilising TACs to guarantee access
to fishing grounds in the presence of future bycatch,
we found that the maxmium effort model effectively 
simulated the TAC under-utilisations for two species 
out of the three.

<!-- We defined a multi-species maximum sustainable yield 
$MSY_{MS,p}$ for each area $p$ by using the relationship 
between trawl fishing effort and species-specific 
fishing mortality rates. For a given value of trawl 
fishing effort $E$, we computed a complex yield curve
by summing the yield curves of all three flatfishes 
in the area at the corresponding fishing mortality rates
\begin{equation}
Y_{MS,p} (E) = \sum_{s} Y_{s,p} (q^{(F)}_{s,p} E),
\end{equation}
where $Y_{MS,p}$ is the complex yield curve for stock
area $p$ with respect to trawl effort, and $Y_{s,p}$ is the
species specific yield curve for stock area $p$ with
respect to fishing mortality. The optimal trawl effort
$E_{MSY,p}$ was then derived as the solution 
to ${dY_{MS,p}}/{dE} = 0$, with corresponding 
equilibrium yield $Y_{MS,p}(E_{MSY,p})$. Our method
is similar to other approaches to defining multi-species 
equilibria [@mueter2006using], but explicitly includes
the differential catchability of technically interacting 
species. -->





## Simulation experiments and performance

For the simulation experiments, we ran a total of $20$
simulations, made up of five assessment models and 
four operating model data scenarios. We ran 100 replicates 
of each OM/MP combination, each initialised with a 
unique random seed, 
thereby integrating over all stochastic processes. To eliminate 
the effect of random variation between simulations, 
each simulation was initialised with the same set
of 100 random seeds. We ran extra replicates until the 
sample size of 100 was reached when AMs failed to
converge in the closed loop simulations, the rate of which
was variable among MPs. The operating model was run for 32 
years, which was two generation lengths for Dover sole, 
the species with the longest generation time in the 
DER complex. Generation time was calculated as the 
average age at maturity of the female spawning population 
in the absence of fishing [@seber1997estimation].

We tested our 20 MPs against a single operating model 
scenario conditioned by the maximum likelihood estimates
of OM assessment. For all DER stocks, the main differences
between OM replicates were in simulated survey observation 
errors and recruitment process error deviations. Simulated 
log-normal observation and process errors were randomly drawn 
with the same standard deviations, and bias corrected so that
asymptotic averages matched the expected value
\begin{align}
I_{s,p,f,t} &= q_{s,p,f} \cdot B_{s,p,f,t} \cdot exp( \tau_{s,p,f} \cdot \delta_{s,p,f,t} - 0.5\tau^2_{s,p,f} ) \\
R_{s,p,t}   &= \hat{R}_{s,p,t} \cdot \cdot exp( \sigma_{s,p} \cdot \epsilon_{s,p,t} - 0.5\sigma^2_{s,p} ) 
\end{align}
where the above variables are defined in Table A1. Recruitment
process errors are simulated from before the end of the
historical period, replacing the equlibrium values used
in years where the conditioning assessment was unable to
estimate process errors due to a lack of age composition
data. 



### Operating model data quality scenarios

Synoptic Survey observation error standard deviation scenarios:

1. half of current SD: $\tau_{s,p,f,proj} = 0.5 \cdot \tau_{s,p,f}$;
2. current $\tau_{s,p,f}$ value from conditioning;
3. twice current SD: $\tau_{s,p,f,proj} = 2 \cdot \tau_{s,p,f}$;

In each scenario, we ramped the simulated Synoptic survey
biomass index observation error standard deviation from 
the historical estimate to the new value over the first 5
years of the projection. Ramping the observation errors
simulated a slow increase or decrease in scientific investment,
rather than an all at once improvement. We used an upper limit
of twice the historical OM standard deviation in our scenarios 
because the average OM observation error SD across all 
stocks was around $0.5$ for the synoptic survey, which was 
already somewhat uninformative, and in preliminary 
simulations we found that the convergence of 
single-stock and hierarchical multi-stock assessment 
model configurations became much lower when Synoptic
trawl survey standard deviations were increased any higher.


### Omniscient manager simulations

We measured our MP performance against a simulated
omniscient manager. An omniscient manager is aware of
all the consequences of their actions, and is able to
adapt the management to meet certain objectives. We found
that comparing to an omnisicient manager was preferable 
to using standard MSE metrics, such as probability of avoiding
limit depletion levels, as most stocks were in a healthy
state (i.e. above $B_{MSY}$). Being in a healthy state 
means that the stock behaves more like
a developing fishery [@walters1998evaluation], and the 
standard catch and biomass depletion metrics are less 
sensitive to differences in the structure of the MP.

We implemented the omniscient manager as an optimisation
of future fishing effort by area, with the objective
function defined as
\begin{equation}
\mathcal{O}  = \sum_{s,p} \left[
                  \begin{array}{l}
                   -\log(\bar{C}_{s,p,\cdot}) + \\ 
                  % \mathcal{P}_{dep}(B_{s,p,t}/B_{MSY,s,p}) +
                  % \mathcal{P}_{closed}(C_{s,p,\cdot}) + \\
                  % \mathcal{P}_{AAV}(C_{s,p,\cdot}) +
                  % \mathcal{P}_{diff}(C_{s,p,\cdot}) +
                    \mathcal{P}_{diff}(\sum_p E_{p,\cdot}) + \\
                  % \mathcal{P}_{init}(C_{s,p,t_{MP}}) +
                    \mathcal{P}_{init}(\sum_p E_{p,t_{MP}}) \end{array} \right]
\end{equation}
where the objective is to maxmimise average catch 
$\bar{C}_{s,p,\cdot}$ for each stock and species over the
projection period. Penalty functions $\mathcal{P}$ were 
applied for:

1. annual changes in total effort across all three areas being above 
20% ($\mathcal{P}_{diff}$).
2. difference between historical effort and first year $t_{MP}$
of simulated effort above 10% ($\mathcal{P}_{init}$).

We defined penalty functions so that inside
the desired region the penalty was zero, but outside
the desired region the penalty grew as a cubic function. 
So, for example, a penalty designed to keep a measurement 
$x$ above a the desired region boundary $\epsilon$ is of 
the form
\begin{equation}
\mathcal{P}(x ~|~ \epsilon) = \left\{
  \begin{array}{ll}
    0 & x \geq \epsilon, \\
    |x - \epsilon|^2 & x < epsilon. \\
  \end{array} \right. 
\end{equation}
This form has a several advantages over
simple linear penalties, or a logarithmic barrier
penalty [@srinivasan2008tracking]. First, the cubic 
function makes the boundary threshold $\epsilon$ a soft 
boundary, which is able to be crossed if doing favours 
another portion of the objective function, and because
cubics stick closer to the $x$-axis when $|x-\epsilon| < 1$
this boundary is softer than lower degree polynomials. Second, 
making the penalty zero in the desirable region stops
the objective function from favouring regions far
from the boundaries of penalty functions, as a logarithmic
function would, for example, favouring overly conservative
effort series to keep biomass far from the lower depletion
boundary. Third, the cubic form of the penalty outside
the desired region means that the penalty function and its
first two derivatives are continuous with $x$ (**CHECK**),
allowing quasi-newton optimisation methods to be applied. Last,
the cubic polynomial actually favours small excursions
outside of the desired region when it is a net increase
in the objective function, as cubics stick closer to the
$x$-axis than lower degree polynomials.

Each penalty function is applied with a weighting, which
we used as tuning parameters. Tuning was required to balance
the relative contribution of each penalty, depending
on whether it was applied to a time series or point value,
and also to achieve realistic time series of effort or catch.
For example, commercial harvesters are unable to double or triple
effort in a short period of time, as this would require significant
capital investment or a large increase in human resources. 
Similarly, in practice harvesters are reluctant to allow catch 
to increase by more than 10% - 20% per year (**REACH OUT TO
TRAWL FOR INPUT/POSSIBLE CITATION HERE**). Similarly,
there are job-security implications for large sudden drops in
fishing effort. **Tuning criteria?**

We used a cubic spline of effort in each area to reduce
the number of free parameters in the optimisation. For each
area, 9 knot points were distributed across the full 40 year
projection, making them spaced by 5 years. We padded
the omniscient manager simulations by an extra eight
years over the stochastic simulations to avoid any
possible end effects of the spline entering the 
performance metric calculations. Effort splines
were constrained to be between 0 and 120 times the
operating model $E_{MSY,p}$, by replacing any value 
outside that range with the closest
value inside the range (i.e. negative values by *zero*,
large values by $120 E_{MSY_p}$).

We ran the omniscient manager simulation for every random
seed that was used in the stochastic MP simulations. By doing so, 
we assured that an omniscient manager simulation was available
for every set of observation and process errors a stochastic MP 
was exposed to.


### Performance metrics


**Consider removing relative loss from the metrics, as
the rankings of MPs are the same under both, and more concrete
to talk about loss in absolute terms**

We measured the performance of the stochastic MPs by comparing
the realised catch and biomass trajectories to those
of the omniscient manager simulations. For each random
seed, the relative and absolute loss of catch and biomass
was calculated as [@walters1998evaluation]:
\begin{align}
L_{abs} &= \sum_{t = T_1}^{T_2} | X_{t,MP} - X_{t,omni} |, \\
L_{rel} &= \sum_{t = T_1}^{T_2} | X_{t,MP} - X_{t,omni}|/X_{t,omni}, 
\end{align}
where the $X_{t,MP}$ values are either catch or spawning
biomass series from the MP runs or the omniscient manager
simulation. Each loss function was calculated on the 
appropriate scale for the MP; that is, the single stock 
and full multi-stock MPs calculate loss for all 9 stocks, 
while the data pooled and coastwide MPs calculate loss on 
the aggregate level. When repeated over all random seed values, 
the loss functions generate a distribution of biomass and 
catch loss, which we compare for performance of each 
stochastic MP.

We calculated loss functions for the ten projection year
period $T_1 = 2026$ to $T_2 = 2035$. We chose a time period 
in the middle of the projection period because loss in the 
earlier time periods is optimistically biased. The bias comes
from the the TAC smoother that restricts TACs from 
increasing by more than 20% in each year.

<!-- We also used the proportion of simulations in which the
assessment model converged as a performance metric. Convergence
rate measures the ability of each model configuration to provide
usable stock assessments at a particular level of data
quality. Indeed, as outlined above, as data quality reduced 
(i.e., observation error variances increased), we found that 
single-stock and hierarchical multi-stock models failed to 
converge on some stocks more often.   -->


## Sensitivity runs

Given the need for informative prior distributions to stabilise
the assessment model behaviour in simulations, we also
conducted some sensitivity analyses. Sensitivity
runs focused on the prior distributions applied to
the Bmsy and Umsy values used in
Sensitivity runs:
1. Bmsy prior CV = 0.1, 0.5, 1.0
2. Random Bmsy prior mean drawn from the conditioning 
assessment's posterior?
3. Loosened prior?


