# Methods

## British Columbia's flatfish fishery

British Columbia's complex of right-eyed flounders is 
a spatially diverse, technically interacting group. While the
there are several right-eyed flounders in BC waters, we 
will focus only on Dover sole (*Microstomus pacficus*), 
English sole (*Parophrys vetulus*), and southern rock sole 
(*Lepidopsetta bilineata*), which we hereafter refer to as rock 
sole. Taken together, we denote the Dover, English and rock sole 
multi-stock complex as the DER complex. We chose the DER complex
as it is managed as part of the BC groundfish fishery, all three 
species have the same management unit boundaries, and are
targeted at different times of the year by the same commercial
bottom trawl fleet. 

The DER complex is managed in three spatially distinct stock
areas, which line up with aggregates of BC groundfish management
areas, which are themselves made up of groups of Pacific Fishery
Management Areas [@PRIFMP2015]. From North to South, the first 
stock area extends from Dixon Entrance, north of Haida Gwaii, 
south through Hecate Strait; we refer to it as the Hecate Strait/Haida 
Gwaii (HSHG) stock, and it corresponds to BC groundfish 
area 5CDE. The second stock area is Queen Charlotte Sound 
(QCS), or BC groundfish area 5AB. Finally, the third
area extends along the West Coast of Vancouver Island (WCVI) 
from its northern tip down to the entrance to Juan de Fuca Strait,
and corresponds to BC groundfish area 3CD. [ADD MAP]

All species in the DER complex have experienced exploitation
since at least 1956 (Figure 1). At that time, Dover sole was only 
lightly exploited, with full commercial exploitation
beginning only in the 1970s (Fig. 1, first column). 
In contrast, English and rock sole fisheries have been 
very active in the HSHG area, where the largest biomass 
is concentrated for those species. English and rock sole
fishing activity in QCS and WCVI areas is more variable 
over time (Figure 1, rows 2 and 3).

Despite a long history of explotitation, and in some cases
recovery from near collapse, most DER complex stocks were 
in state more like developing fisheries in 2016 [REF].
All DER complex stocks were in a healthy state, with
current spawning biomasses above 80% of $B_{MSY}$, and 
all but three cases at or above $B_{MSY}$ (Table 1). 
Moreover, some stocks were actively recovering from their
historic low biomasses, like English sole in HSHG, and 
Rock sole in HSHG and WCVI.



## Simulation model framework

Our simulation framework had an operating
model component and management procedure component. The
stochastic operating model simulated the responses of a 
spatially stratified multi-species complex of fishes to 
trawl fleet fishing effort in each of the three stock areas. 
Total fishing effort was not restricted, but the effort in each  
area was allocated so that no catch exceeded the TAC for 
any species in that area, but at least one species' 
TAC was fully utilised in each area.

Our closed loop simulations applied the management 
procedure iteratively in the following 5 steps 
over the $T$ years of the projection:

1. Apply an assessment method to determine stock
status of the full 9 stock complex, either using data pooling,
hierarchical assessments, or single-stock assessments; 
2. Apply a harvest control rule to determine
total allowable catch, and then allocate TAC 
among species if using a data-pooling method;
3. Allocate effort to fully realise at least
one TAC in each stock area;
4. Generate realised catches from effort with
updated catch rates;
5. Update stochastic population dynamics and
generate new observation data.

Each set of $T$ projection years was repeated
100 times to integrate over observation errors 
and recruitment process errors. When replicates
included time steps where assessment models would 
not converge (largely due to data quality issues)
we increased the number of replicates until we reached
100 replicates where simulated assessment models 
converged for all time steps.

### Operating Model

The operating model (OM) component was a multi-species,
multi-stock age- and sex-structured population dynamics model 
(Appendix A). We conditioned the OM by fitting it as 
a stock assessment model to commercial and survey data
for the DER complex, including commercial catch, CPUE,
and catch-at-age/length, and fishery independent survey 
biomass indices, and survey catch-at-age/length. Given 
the low volume of biological data from recent time 
periods, we used a hierarchical multi-species and multi-stock
assessment model formulation with shrinkage priors on 
natural mortality, stock-recruitment steepness, 
trawl survey catchability, and selectivity-at-length 
parameters. We refer readers to Appendix A for a more 
detailed exposition.

#### Fishing effort, fishing mortality, and optimal yield

We allocated maximum fishing effort to each area. 
Maximum effort was defined as the amount required to
fully utilise the TAC of at least one species, 
but never exceed any of the three species' TACs. 
Effort was then supplied to the operating model to
generate realised fishing mortality among
species and stock areas as
\begin{equation}
F_{s,p,f,t} = \bar{q}^{(F)}_{s,p,f} * E_{p,f,t},
\end{equation}
where $\bar{q}^{(F)}_{s,p,f}$ is the 
ratio of estimated fishing mortality rates to 
fishing effort in the last year of the conditioning 
assessment. Historical fishing effort was estimated by taking 
the average ratio
\begin{equation}
E_{p,f,t} = \bar{\frac{C_{s,p,f,t}}{I'_{s,p,f,t}}}
\end{equation}
where $I'_{s,p,f,t}$ is unstandardized commercial
CPUE (in kg/hour), and $C_{s,p,f,t}$ is the total 
catch in kt. We averaged this ratio over species within a stock area to 
account for years in which there were missing CPUE
observations (**WHY NOT TAKE MAX?? WHAT ABOUT SMOOTHING??
CHECK UNITS, COULD PROBABLY DO WITH A PLOT**).

We chose to use maximum effort over an effort dynamics
model because of (i) its simplicity and (ii) its similarity 
to other MSE simulations for BC fisheries. We considered 
including an effort dynamics model to allocate a pool 
of effort over the three areas [@hilborn1987general;
@walters1999multispecies], but determined that this was
not necessary for determining the management performance 
of the multiple assessment models that we are testing.
Furthermore, although the BC groundfish fishery balances
the utilisation of many more than three TACs in practice,
avoiding fully utilising TACs to account for future bycatch,
we found that the maxmium effort model effectively 
simulated the TAC under-utilisations for two species 
out of the three. Finally, BC sablefish, herring, and
outside yelloweye rockfish use full TAC utilisation 
in their management simulations
[@cox2019evaluating;**INSERT HERRING and OYE CSAS HERE**],
under the assumption that full TAC utilisation provides
and upper bound on the management risk.

We defined a multi-species maximum sustainable yield 
$MSY_{MS,p}$ for each area $p$ by using the relationship 
between trawl fishing effort and species-specific 
fishing mortality rates. For a given value of trawl 
fishing effort $E$, we computed a complex yield curve
by summing the yield curves of all three flatfishes 
in the area at the corresponding fishing mortality rates
\begin{equation}
Y_{MS,p} (E) = \sum_{s} Y_{s,p} (q^{(F)}_{s,p} E),
\end{equation}
where $Y_{MS,p}$ is the complex yield curve for stock
area $p$ with respect to trawl effort, and $Y_{s,p}$ is the
species specific yield curve for stock area $p$ with
respect to fishing mortality. The optimal trawl effort
$E_{MSY,p}$ was then derived as the solution 
to ${dY_{MS,p}}/{dE} = 0$, with corresponding 
equilibrium yield $Y_{MS,p}(E_{MSY,p})$. Our method
is similar to other approaches to defining multi-species 
equilibria [@mueter2006using], but explicitly includes
the differential catchability of technically interacting 
species.

### Management Procedures

We tested ten management procedures in total,
which were made up of a factorial combination
of five surplus production stock assessment models
and two target harvest rates (Table X). Assessment models and
target harvest rates are defined in the following
sections. We chose to restrict
ourselves to this small set, as this would
allow us to focus on the management performance
of the range of models and the two harvest rates 
under different data quality scenarios, rather than 
the interaction between the assessment model and 
other management procedure components.

#### Surplus production stock assessment models

Management procedures determined stock
status using a flexible process-error surplus 
production model. The flexibility allowed the
same model to be used for all assessment complex
configurations, ranging from data-pooled single
stock assessments with no shrinkage priors to hierarchical
multi-species and multi-stock assessments. We defined this
model in Template Model Builder, extending
a model from our previous research [@kristensen2015tmb;
@johnson2018evaluating]. For hierarchical model formulations, 
we applied shrinkage priors to survey catchability 
and intrinsic growth rate (Appendix B). In total,
five model configurations were defined:

1. Hierarchical multi-stock (9 stocks, sharing info)
2. Single-stock (9 stocks, independent)
3. Hierarchical coastwide (3 species)
4. Hierarchical data-pooled (3 stocks)
5. Data-pooled coastwide (1 stock)


Data was pooled by simple summation of both
catch and biomass indices across species within
each area. This reflects that each species' survey 
biomass index was an estimate of trawlable biomass, 
so the pooled index was an estimate of trawlable
complex biomass available to the survey. We also
summed the CPUE observations for the commercial
trawl fleets, under the assumption that the same
trawl effort was used to calculate the unstandardised
CPUE observations (i.e. the CPUE series had the same
denominators); however, this assumption was inaccurate 
as the species-specific CPUE had species-specific effort
derived from the fishing sets that caught each species, 
and not all fishing sets catch all three species. Ignoring 
the inaccuracy biased the data-pooled CPUE and introduced
more variability, which we decided was acceptable
for research purposes. Under coastwide assessments, 
each survey (pooled or separate) was considered as a 
separate index of the same population.

We extended our surplus production stock assessment model 
to account for differences between the operating model
dynamics and the assessment model assumptions about
yield curve shape and ratios of exploitable biomass
to spawning biomass. We followed the JABBBA-Select
formulation for biomass assessments to add both
features [@winker2020jabba]. Skew in the operating 
model yield curves was added to all AMs by switching to
a Pella-Tomlinson formulation [@pella1969generalized], 
and the difference between exploitable biomass and 
spawning biomass was added by using the equilibrium 
model developed for the JABBA-Select model 
[@winker2020jabba]. We used the skewed yield curve
for all model formulations, including data aggregated
methods, where we re-derived the ratio between unfished
and optimal biomass in each case. The exploitable
and spawning biomass ratio estimates were used in all cases
except the data-pooling, spatially disaggregated 
assessment (3 in above list), under which the 
estimates introduced a persistent bias in the fits
to stock indices. Details of our derivation
of skew and biomass ratio parameters are given in 
Appendix B.

At each time step $t$, the AM estimated production model 
equilibria $B_{MSY}$ and $U_{MSY}$, and an expected 
biomass estimate $\hat{B}_{t+1}$ for the following 
time step.


#### Harvest control rule

To set catch limits for a given stock, or data-pooled complex,
we applied a constant target harvest rate. We tested two
harvest rates, which were either the single-species $U_{MSY,SS}$,
or multi-species $U_{MSY,MS}$ optimal harvest rates derived 
from operating model equilibrium yield curves. We computed
optimal harvest rates for data-pooled or coast-wide assessment 
model structures by summing the optimal yield $MSY$ and 
exploitable biomass $B_{MSY}$ values of the component 
stocks, e.g. for a data pooled complex in the HSHG stock area,
the multi-species optimal harvest rate was calculated as
\begin{equation}
U_{MSY,HSHG,MS} = \frac{\sum_{s} MSY_{s,HSHG,MS} }{ \sum_{s} B_{MSY,s,HSHG,MS} },
\end{equation}
where $MSY_{s,HSHG,MS}$ is the optimal yield for species $s$
in the HSHG stock area from the multi-species effort-yield
curve defined in section X above, and $B_{MSY,s,HSHG,MS}$ is
the equilibrium spawning biomass that produces $MSY_{s,HSHG,MS}$.

<!-- ramped precuationary harvest control 
rule, following Canadian federal policy [@DFO2006A-Harvest-Strat]:
\begin{equation},
U_{t+1} = \left\{ \begin{array}{ll}
            0 & \hat{B}_{t+1} \leq .4\hat{B}_{MSY} \\
            \frac{\hat{B}_{t+1} - .4\hat{B}_{MSY}}{(.6 - .4)\hat{B}_{MSY}} U_{MSY} & 
                .4 < \hat{B}_{t+1}/\hat{B}_{MSY} \leq .6 \\
            \hat{U}_{MSY} & \hat{B}_{t+1} \geq .6\hat{B}_{MSY}
          \end{array} \right.
\end{equation}
Where $\hat{B}_{MSY}$, $\hat{U}_{MSY}$, and $\hat{B}_{t+1}$  
were estimated by the assessment model either for 
an individual species, individual stocks, or a 
data-pooled complex. -->

Total allowable catch (TAC) was then set as the product
of target harvest rate and projected biomass
\begin{equation}
TAC_{t+1} = U \cdot \hat{B}_{t+1},.
\end{equation}
where $U$ is the optimal harvest rate for either the 
single-species or multi-species equilibrium yield curves,
and stock aggregation level. In management procedures where 
the assessment model estimated biomass for each individual 
stock (i.e. single-stock and hierarchical multi-stock AMs), 
then TACs were passed directly to the effort allocation 
model. In the remaining procedures where data were pooled or 
stock structure was ignored, we allocated the pooled TAC 
among areas and species.  **DELTA TAC UP**

For splitting TACs within an area or across spatial
strata when data had been pooled, we split them according to 
the relative contribution of each individual index to the 
pooled data. For example, if the pooled biomass 
index for stock area $p$ in time step $t$ was the sum of species
specific indices in the same area, i.e,
\begin{equation}
I_{p,t} = \sum_s I_{s,p,t},
\end{equation}
then the TAC for species $s$ is apportioned as
\[
TAC_{s,p,t+1} = \frac{I_{s,p,t}}{I_{p,t}} TAC_{p,t+1}.
\]
The analogous apportionment holds for all data aggregation
MPs.


## Simulation experiments and performance

For the simulation experiments, we ran a total of $30$
simulations, made up of ten factorial combinations 
of the five assessment models and two harvest control
rule settings, and three operating model observation
error variance scenarios. We ran 100 replicates of each OM/MP
combination, each initialised with a unique random seed, 
thereby integrating over all stochastic processes. To eliminate 
the effect of random variation between simulations, 
each simulation was initialised with the same set
of 100 random seeds. We ran extra replicates until the 
sample size of 100 was reached when AMs failed to
converge in the closed loop simulations, the rate of which
was variable among MPs. The operating model was run for 32 
years, which was two generation lengths for Dover sole, 
the species with the longest generation time in the 
DER complex. Generation time was calculated as the 
average age at maturity of the female spawning population 
in the absence of fishing [@seber1997estimation].

We tested our 20 MPs against a single operating model 
scenario conditioned by the maximum likelihood estimates
of OM assessment. For all DER stocks, the main differences
between OM replicates were in simulated survey observation 
errors and recruitment process error deviations. Simulated 
log-normal observation and process errors were randomly drawn 
with the same standard deviations, and bias corrected so that
asymptotic averages matched the expected value
\begin{align}
I_{s,p,f,t} &= q_{s,p,f} \cdot B_{s,p,f,t} \cdot exp( \tau_{s,p,f} \cdot \delta_{s,p,f,t} - 0.5\tau^2_{s,p,f} ) \\
R_{s,p,t}   &= \hat{R}_{s,p,t} \cdot \cdot exp( \sigma_{s,p} \cdot \epsilon_{s,p,t} - 0.5\sigma^2_{s,p} ) 
\end{align}
where the above variables are defined in Table A1. Recruitment
process errors are simulated from before the end of the
historical period, replacing the equlibrium values used
in years where the conditioning assessment was unable to
estimate process errors due to a lack of age composition
data. 



### Operating model data quality scenarios

Synoptic Survey observation error standard deviation scenarios:

1. half of current SD: $\tau_{s,p,f,proj} = 0.5 \cdot \tau_{s,p,f}$;
2. current $\tau_{s,p,f}$ value from conditioning;
3. twice current SD: $\tau_{s,p,f,proj} = 2 \cdot \tau_{s,p,f}$;

In each scenario, we ramped the simulated Synoptic survey
biomass index observation error standard deviation from 
the historical estimate to the new value over the first 5
years of the projection. Ramping the observation errors
simulated a slow increase or decrease in scientific investment,
rather than an all at once improvement. We used an upper limit
of twice the historical OM standard deviation in our scenarios 
because the average OM observation error SD across all 
stocks was around $0.5$ for the synoptic survey, which was 
already somewhat uninformative, and in preliminary 
simulations we found that the convergence of 
single-stock and hierarchical multi-stock assessment 
model configurations became much lower when Synoptic
trawl survey standard deviations were increased any higher.


### Omniscient manager simulations

We measured our MP performance against a simulated
omniscient manager. An omniscient manager is aware of
all the consequences of their actions, and is able to
adapt the management to meet certain objectives. We found
that comparing to an omnisicient manager was preferable 
to using standard MSE metrics, such as probability of avoiding
limit depletion levels, as most stocks were in a healthy
state (i.e. above $B_{MSY}$). Being in a healthy state 
means that the stock behaves more like
a developing fishery [@walters1998evaluation], and the 
standard catch and biomass depletion metrics are less 
sensitive to differences in the structure of the MP.

We implemented the omniscient manager as an optimisation
of future fishing effort by area, with the objective
function defined as
\begin{equation}
\mathcal{O}  = \sum_{s,p} \left[
                  \begin{array}{l}
                   -\log(\bar{C}_{s,p,\cdot}) + \\ 
                  % \mathcal{P}_{dep}(B_{s,p,t}/B_{MSY,s,p}) +
                  % \mathcal{P}_{closed}(C_{s,p,\cdot}) + \\
                  % \mathcal{P}_{AAV}(C_{s,p,\cdot}) +
                  % \mathcal{P}_{diff}(C_{s,p,\cdot}) +
                    \mathcal{P}_{diff}(\sum_p E_{p,\cdot}) + \\
                  % \mathcal{P}_{init}(C_{s,p,t_{MP}}) +
                    \mathcal{P}_{init}(\sum_p E_{p,t_{MP}}) \end{array} \right]
\end{equation}
where the objective is to maxmimise average catch 
$\bar{C}_{s,p,\cdot}$ for each stock and species over the
projection period. Penalty functions $\mathcal{P}$ were 
applied for:

1. annual changes in total effort across all three areas being above 
20% ($\mathcal{P}_{diff}$).
2. difference between historical effort and first year $t_{MP}$
of simulated effort above 10% ($\mathcal{P}_{init}$).

We defined penalty functions so that inside
the desired region the penalty was zero, but outside
the desired region the penalty grew as a cubic function. 
So, for example, a penalty designed to keep a measurement 
$x$ above a the desired region boundary $\epsilon$ is of 
the form
\begin{equation}
\mathcal{P}(x ~|~ \epsilon) = \left\{
  \begin{array}{ll}
    0 & x \geq \epsilon, \\
    |x - \epsilon|^2 & x < epsilon. \\
  \end{array} \right. 
\end{equation}
This form has a several advantages over
simple linear penalties, or a logarithmic barrier
penalty [@srinivasan2008tracking]. First, the cubic 
function makes the boundary threshold $\epsilon$ a soft 
boundary, which is able to be crossed if doing favours 
another portion of the objective function, and because
cubics stick closer to the $x$-axis when $|x-\epsilon| < 1$
this boundary is softer than lower degree polynomials. Second, 
making the penalty zero in the desirable region stops
the objective function from favouring regions far
from the boundaries of penalty functions, as a logarithmic
function would, for example, favouring overly conservative
effort series to keep biomass far from the lower depletion
boundary. Third, the cubic form of the penalty outside
the desired region means that the penalty function and its
first two derivatives are continuous with $x$ (**CHECK**),
allowing quasi-newton optimisation methods to be applied. Last,
the cubic polynomial actually favours small excursions
outside of the desired region when it is a net increase
in the objective function, as cubics stick closer to the
$x$-axis than lower degree polynomials.

Each penalty function is applied with a weighting, which
we used as tuning parameters. Tuning was required to balance
the relative contribution of each penalty, depending
on whether it was applied to a time series or point value,
and also to achieve realistic time series of effort or catch.
For example, commercial harvesters are unable to double or triple
effort in a short period of time, as this would require significant
capital investment or a large increase in human resources. 
Similarly, in practice harvesters are reluctant to allow catch 
to increase by more than 10% - 20% per year (**REACH OUT TO
TRAWL FOR INPUT/POSSIBLE CITATION HERE**). Similarly,
there are job-security implications for large sudden drops in
fishing effort. **Tuning criteria?**

We used a cubic spline of effort in each area to reduce
the number of free parameters in the optimisation. For each
area, 9 knot points were distributed across the full 40 year
projection, making them spaced by 5 years. We padded
the omniscient manager simulations by an extra eight
years over the stochastic simulations to avoid any
possible end effects of the spline entering the 
performance metric calculations. Effort splines
were constrained to be between 0 and 120 times the
operating model $E_{MSY,p}$, by replacing any value 
outside that range with the closest
value inside the range (i.e. negative values by *zero*,
large values by $120 E_{MSY_p}$).

We ran the omniscient manager simulation for every random
seed that was used in the stochastic MP simulations. By doing so, 
we assured that an omniscient manager simulation was available
for every set of observation and process errors a stochastic MP 
was exposed to.


### Performance metrics


**Consider removing relative loss from the metrics, as
the rankings of MPs are the same under both, and more concrete
to talk about loss in absolute terms**

We measured the performance of the stochastic MPs by comparing
the realised catch and biomass trajectories to those
of the omniscient manager simulations. For each random
seed, the relative and absolute loss of catch and biomass
was calculated as [@walters1998evaluation]:
\begin{align}
L_{abs} &= \sum_{t = T_1}^{T_2} | X_{t,MP} - X_{t,omni} |, \\
L_{rel} &= \sum_{t = T_1}^{T_2} | X_{t,MP} - X_{t,omni}|/X_{t,omni}, 
\end{align}
where the $X_{t,MP}$ values are either catch or spawning
biomass series from the MP runs or the omniscient manager
simulation. Each loss function was calculated on the 
appropriate scale for the MP; that is, the single stock 
and full multi-stock MPs calculate loss for all 9 stocks, 
while the data pooled and coastwide MPs calculate loss on 
the aggregate level. When repeated over all random seed values, 
the loss functions generate a distribution of biomass and 
catch loss, which we compare for performance of each 
stochastic MP.

We calculated loss functions for the ten projection year
period $T_1 = 2026$ to $T_2 = 2035$. We chose a time period 
in the middle of the projection period because loss in the 
earlier time periods is optimistically biased. The bias comes
from the the TAC smoother that restricts TACs from 
increasing by more than 20% in each year.

<!-- We also used the proportion of simulations in which the
assessment model converged as a performance metric. Convergence
rate measures the ability of each model configuration to provide
usable stock assessments at a particular level of data
quality. Indeed, as outlined above, as data quality reduced 
(i.e., observation error variances increased), we found that 
single-stock and hierarchical multi-stock models failed to 
converge on some stocks more often.   -->


## Sensitivity runs

Given the need for informative prior distributions to stabilise
the assessment model behaviour in simulations, we also
conducted some sensitivity analyses. Sensitivity
runs focused on the prior distributions applied to
the Bmsy and Umsy values used in
Sensitivity runs:
1. Bmsy prior CV = 0.1, 0.5, 1.0
2. Random Bmsy prior mean drawn from the conditioning 
assessment's posterior?
3. Loosened prior?


